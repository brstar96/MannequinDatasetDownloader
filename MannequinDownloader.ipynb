{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mannequin Challenge Dataset Downloader\n",
    "This notebook is a downloader for Mannequin Challenge Dataset. Written by Myeong-Gyu.Lee\n",
    "\n",
    "* Reference: https://blog.naver.com/PostView.nhn?blogId=skyshin0304&logNo=221620513883&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
    "\n",
    "type `pip install pytube3` to install pytube library.\n",
    "\n",
    "### Test single video download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from tqdm import tqdm\n",
    "import os, cv2, shutil, math, datetime, ast, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_url = 'https://www.youtube.com/watch?v=KMtgexdtcGY'\n",
    "yt = YouTube(_url)\n",
    "print(\"영상 제목 :\", yt.title)\n",
    "print(\"영상 길이 :\", yt.length)\n",
    "print(\"영상 평점 :\", yt.rating)\n",
    "print(\"영상 썸네일 링크: \", yt.thumbnail_url)\n",
    "print(\"영상 조회수 :\", yt.views)\n",
    "print(\"영상 설명 :\", yt.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_yt_streams = yt.streams\n",
    "print(\"다운가능한 영상 상세 정보 :\")\n",
    "for i, stream in enumerate(_yt_streams.all()):\n",
    "    print(i, \" : \", stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the dataframe and sort by `res` to get highest resolution video.\n",
    "Get only `video/mp4` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    entire_frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    return entire_frame_count, width, height, fps, video\n",
    "\n",
    "def save_frames(case_name, meta_txt, video, target_frames_path):\n",
    "    target_frames_path = os.path.join(target_frames_path, case_name)\n",
    "    os.makedirs(target_frames_path, exist_ok=True)\n",
    "    lines = meta_txt.readlines()\n",
    "    for index, line in enumerate(lines):\n",
    "        row_str = line.replace('\\n', '') \n",
    "        if not 'https' in line:\n",
    "            microsecond_info = int(row_str.split(' ')[0])\n",
    "            frame_number = math.floor(round(int(microsecond_info)/1000000, 3)*29.97)\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, frame_number-1)\n",
    "            ret, frame = video.read() # Read the frame\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            cv2.imwrite(os.path.join(target_frames_path, case_name + '_' + str(index) + '.png'), frame)\n",
    "    meta_txt.close()\n",
    "\n",
    "def get_download_info(yt_streams, video_url):\n",
    "    stream_df_list = []\n",
    "    \n",
    "    for stream in yt_streams:\n",
    "        try:\n",
    "            stream_dict = dict()\n",
    "            stream_str = str(stream)\n",
    "            stream_elements = stream_str.replace('Stream: ', '').replace('=', ':').replace('<', '').replace('>', '').replace('\"', '').split(' ')\n",
    "            for elemnt in stream_elements:\n",
    "                stream_dict[elemnt.split(':')[0]] = elemnt.split(':')[-1]\n",
    "            stream_df_list.append(pd.DataFrame.from_dict(stream_dict, orient='index').T)\n",
    "        except:\n",
    "            print(\"This yt_stream does not have any downloadable streams.\")\n",
    "\n",
    "    stream_df_global = pd.concat(stream_df_list)\n",
    "    stream_df_global['videoID'] = str(video_url.split('/')[-1].split('=')[-1])\n",
    "    stream_df_global.set_index('videoID', inplace = True)\n",
    "    stream_df_global = stream_df_global[pd.notnull(stream_df_global['res'])]\n",
    "    stream_df_global['res'] = stream_df_global['res'].str.replace(pat=r'[A-Za-z]', repl= r'', regex=True)\n",
    "    stream_df_global = stream_df_global.astype({'itag': int, 'res': int})\n",
    "    stream_df_global = stream_df_global.sort_values(by='res', ascending=False)\n",
    "    stream_df_global = stream_df_global[stream_df_global['mime_type'] == 'video/mp4']\n",
    "    \n",
    "    # itag를 이용해 가장 높은 해상도의 Video Download\n",
    "    highest_stream = yt_streams.get_by_itag(stream_df_global.iloc[0]['itag'])\n",
    "    \n",
    "    return stream_df_global, highest_stream\n",
    "\n",
    "# Read txt file to fetch youtube video stream. After fetching stream, save video with single frames.\n",
    "def dataset_downloader(meta_file_path, target_video_path, target_frames_path):\n",
    "    failed_video_urls = {}\n",
    "    \n",
    "    for path in os.listdir(meta_file_path):\n",
    "        failure_url_list = []\n",
    "        txt_path = os.path.join(meta_file_path, path)\n",
    "        for txt in tqdm(os.listdir(txt_path)):\n",
    "            f = open(os.path.join(txt_path, txt))\n",
    "            video_url = f.readline().replace('\\n', '')\n",
    "            \n",
    "            try:\n",
    "                output_path = os.path.join(target_video_path, path)\n",
    "                os.makedirs(output_path, exist_ok=True)\n",
    "                \n",
    "                # Get youtube video stream informations.\n",
    "                yt_streams = YouTube(video_url)\n",
    "                _yt_str = yt_streams.streams\n",
    "                stream_df_global, highest_stream = get_download_info(_yt_str, video_url)\n",
    "                filename = stream_df_global.index[0]\n",
    "                \n",
    "                if not os.path.exists(os.path.join(output_path, filename+'.mp4')):\n",
    "                    highest_stream.download(output_path=output_path, filename=filename)\n",
    "                else:\n",
    "                    print(\"This stream is exist: {}\".format(filename+'.mp4'))\n",
    "                    continue\n",
    "            except:\n",
    "                print(\"This stream is not downloadable: {}\".format(filename))\n",
    "                failure_url_list.append(filename)\n",
    "                continue\n",
    "            \n",
    "            failed_video_urls.update({path:failure_url_list})\n",
    "            entire_frame_count, width, height, fps, video = get_video_info(os.path.join(output_path, filename+'.mp4'))\n",
    "            \n",
    "            output_frame_path = os.path.join(target_frames_path, path)\n",
    "            os.makedirs(output_frame_path, exist_ok=True)\n",
    "            save_frames(case_name=txt.split('.')[0], meta_txt=f, video=video, target_frames_path=output_frame_path)\n",
    "            \n",
    "    return failed_video_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df_global, highest_stream = get_download_info(_yt_streams, _url)\n",
    "print('Highest resolution stream info:', highest_stream)\n",
    "stream_df_global.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"선택된 stream 다운로드:\", highest_stream)\n",
    "# highest_stream.download(output_path='D:/MannequinChallenge_Videos', filename=stream_df_global.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read whole `.txt` file and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'D:/MannequinChallenge'\n",
    "meta_file_path = 'D:/MannequinChallenge/meta_files'\n",
    "target_video_path = os.path.join(root_path, 'original_videos')\n",
    "target_frames_path = os.path.join(root_path, 'original_sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_video_urls = dataset_downloader(meta_file_path, target_video_path, target_frames_path)\n",
    "\n",
    "print(\"Done downloading videos! \\nFailure video summary: \\n - train: {}, - val: {}, - test: {}\".format(\n",
    "                len(failed_video_urls['train']), \n",
    "                len(failed_video_urls['validation']),\n",
    "                len(failed_video_urls['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
